{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc6tRBTgQyNN"
      },
      "source": [
        "# Week 7: Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0_pIxYZQyNV"
      },
      "source": [
        "In this practice session, we will cover implementation of Convolutional Neural Networks (CNNs) using PyTorch library. Particulary, in part 1, we will see how to define and use convolutional, batch normalization, and dropout layer to build a simple CNNs to classify MNIST. In part 2, we will implement ResNet for CIFAR-10 classification task and see the effectiveness of residual connection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5ek3kYjQyNX"
      },
      "source": [
        "## 0. Preliminary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kD_QPeQQyNY"
      },
      "source": [
        "Let's import required libraries and datasets. We will use MNIST and CIFAR-10 to train a simple CNNs and ResNet, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2Lexa2yQyNZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from IPython.display import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2Wqi2AqQyNb"
      },
      "outputs": [],
      "source": [
        "# MNIST\n",
        "mnist_train = MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "mnist_test = MNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "mnist_train, mnist_val = torch.utils.data.random_split(mnist_train, [50000, 10000])\n",
        "\n",
        "dataloaders = {}\n",
        "dataloaders['train'] = DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
        "dataloaders['val'] = DataLoader(mnist_val, batch_size=128, shuffle=False)\n",
        "dataloaders['test'] = DataLoader(mnist_test, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER-_GB9VQyNd"
      },
      "source": [
        "In case of CIFAR-10, we use conventional transforms and normalization.\n",
        "\n",
        "For more example, please refer to\n",
        "https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pya9DvQQyNe"
      },
      "outputs": [],
      "source": [
        "transforms_train = transforms.Compose([\n",
        "  transforms.RandomCrop(32, padding=4),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "transforms_test = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "cifar_train = CIFAR10(root='./', train=True,\n",
        "            download=True, transform=transforms_train)\n",
        "cifar_test = CIFAR10(root='./', train=False,\n",
        "             download=True, transform=transforms_test)\n",
        "cifar_loader = {}\n",
        "cifar_loader['train'] = DataLoader(cifar_train, batch_size=128,\n",
        "                        shuffle=True, num_workers=4)\n",
        "cifar_loader['test'] = DataLoader(cifar_test, batch_size=128,\n",
        "                       shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAIWKAabQyNg"
      },
      "source": [
        "## 1. Convolutional, Batch Norm and Dropout Layer Practice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fziaEn4WQyNh"
      },
      "source": [
        "### 1.1. Convolutional Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3kuo0IdQyNi"
      },
      "source": [
        "In PyTorch, 2-dimensional convolutional layer is given with the pytorch `torch.nn.Conv2d` package. In this section, we will learn basic usage of pytorch convolutional layer with some example codes and practices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGnri0gmQyNj"
      },
      "source": [
        "As in our lecture session, we should specify convolution with the number of channels of input and output, kernel size, the size of stride and padding. In Pytorch `torch.nn.Conv2d` class, those traits can be specified as class parameters. The detailed explanation and default values are available on below and the official sites (https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcaiNXVBQyNk"
      },
      "source": [
        "* in_channels (int) – Number of channels in the input image\n",
        "\n",
        "* out_channels (int) – Number of channels produced by the convolution\n",
        "\n",
        "* kernel_size (int or tuple) – Size of the convolving kernel\n",
        "\n",
        "* stride (int or tuple, optional) – Stride of the convolution. Default: 1\n",
        "\n",
        "* padding (int or tuple, optional) – Zero-padding added to both sides of the input. Default: 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTZ4U1HxQyNl"
      },
      "source": [
        "Now, let's define our convolutional layer and practice. As in our lecture note, let's suppose we have 32x32-sized image with 3 channels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRKJ-BWGQyNm"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Note: Since PyTorch Conv2d receives 4-dimensional input (i.e. a batch of image(s)),\n",
        "we define input x with the first argument 1.\n",
        "\"\"\"\n",
        "x = torch.randn(1, 3, 32, 32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HXXkRH_QyNn"
      },
      "source": [
        "Then, the number of input channel is 3, which is the same value with the input images' channel (the second argument of above `randn` method).\n",
        "\n",
        "How about the number of output channel, kernel and stride size? Following the figure in our lecture note, we can easily see that the number of output channel should be 1. You can naively regard the kernel size as the spatial size of filter in the lecture note. Thus, the kernel size should be (5,5), and the stride size should be 1. In practice, since the spatial size of filter in in square form (i.e., width = height), we usually specifiy kernel size with only single integer (in our case 5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpG1HWF9QyNp"
      },
      "outputs": [],
      "source": [
        "# Fill out the ?? of below\n",
        "conv_layer = torch.nn.Conv2d(in_channels=??, out_channels=??, kernel_size=??,padding=??, stride=??)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr2DhN6bQyNp"
      },
      "outputs": [],
      "source": [
        "# You should check the output size of covolution layer is [1, 1, 28, 28].\n",
        "conv_layer(x).size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u42vM94LQyNp"
      },
      "source": [
        "Also check the other example in the lecture note as below.\n",
        "* Input volume: 3x32x32\n",
        "* 10 5x5 filters with stride 1, pad 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PT3-Y53eQyNq"
      },
      "outputs": [],
      "source": [
        "# Fill out the ?? of below\n",
        "x = torch.randn(??, ??, ??, ??)\n",
        "conv_layer = torch.nn.Conv2d(??)\n",
        "print(conv_layer(x).size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vm_HrO1xQyNq"
      },
      "source": [
        "### 1.2. BatchNorm and Dropout layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWVnzNXtQyNq"
      },
      "source": [
        "In a similar manner, batch normalization and dropout layer also can be used from `torch.nn.BatchNorm2d` and `torch.nn.Dropout2d`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3QOd_2VQyNr"
      },
      "outputs": [],
      "source": [
        "x = torch.randn(1, 3, 32, 32)\n",
        "\n",
        "bn = torch.nn.BatchNorm2d(num_features=?)\n",
        "print(bn(x).size()) # check batch norm does not change the size of input\n",
        "\n",
        "dropout = torch.nn.Dropout2d(p=0.5) # dropout can specify probability of an element to be zeroed.\n",
        "print(dropout(bn(x)).size()) # check dropout does not change the size of input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Provide some evidences for the implementation of BatchNorm & DropOut\n",
        "\"\"\"\n",
        "def show_evidence_plot_for_batch_norm():\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    x = torch.randn(128, 3, 32, 32)\n",
        "    x = x * 100  # amplify\n",
        "    bn = nn.BatchNorm2d(num_features=3)\n",
        "    assert x.size() == bn(x).size()\n",
        "\n",
        "    x_c1 = x[:,0,:,:].flatten()\n",
        "    bn_x_c1 = bn(x)[:,0,:,:].detach().flatten()\n",
        "\n",
        "    plt.hist(x_c1, bins=20)\n",
        "    plt.title(f\"mean={x_c1.mean():.4f}, std={x_c1.std():.2f}\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.hist(bn_x_c1, bins=20)\n",
        "    plt.title(f\"mean={bn_x_c1.mean():.4f}, std={bn_x_c1.std():.2f}\")\n",
        "    plt.show()\n",
        "\n",
        "show_evidence_plot_for_batch_norm()"
      ],
      "metadata": {
        "id": "VSK0TWZs_Bqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ja8skHpQyNr"
      },
      "source": [
        "### 1.3. Build a Simple Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67q1DH3tQyNr"
      },
      "source": [
        "We can combine convolution layer, batch norm layer and activation function (e.g., ReLU) to construct a functional unit. In this case, we can use `torch.nn.Sequential` to define a block of sequential layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnOsJpaDQyNr"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 32 output channels, 7x7 square convolution, 1 stride\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(???),\n",
        "            nn.BatchNorm2d(???),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        # 32 input image channel, 64 output channels, 7x7 square convolution, 1 stride\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(???),\n",
        "            nn.BatchNorm2d(???),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Linear(??, ??)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aJTgOtjQyNr"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "net = Net().to(device)\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAue1RyHQyNs"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7KbRMb4QyNs"
      },
      "outputs": [],
      "source": [
        "for _ in range(20):\n",
        "    for x, y in dataloaders['train']:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        out = net(x)\n",
        "        loss = criterion(out, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlRCfA8cQyNs"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "correct = 0.0\n",
        "for x, y in dataloaders['test']:\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    out = net(x)\n",
        "    correct += (out.argmax(1) == y).float().sum().item()\n",
        "print(100. * correct / len(dataloaders['test'].dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaCE63MlQyNs"
      },
      "source": [
        "## 2. CNN Architecture: ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q785wAjkQyNs"
      },
      "source": [
        "In this section, we will implement ResNet and see the effectiveness of residual connection in terms of test performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htJM24PqQyNt"
      },
      "source": [
        "The overall structure of ResNet is like below.\n",
        "\n",
        "* input(channel:3) -> (conv 3x3) -> (bn) -> (relu) -> output(channel:16)\n",
        "* n Residual blocks: (16 channels -> 16 channels)\n",
        "* n Residual blocks: (16 channels -> 32 channels)\n",
        "* n Residual blocks: (32 channels -> 64 channels)\n",
        "* global average pooling + fully connected layer\n",
        "\n",
        "n can be chosen from {3,5,7,9,18} which of each corresponds to ResNet-20, 32, 44, 56, and 110, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXAiunN1QyNt"
      },
      "source": [
        "### 2.1. Residual Block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSQK3VqaQyNt"
      },
      "source": [
        "Residual Block consists of 2 convolution layers with 3x3 size kernel and ReLU activation function. Let's implement `ResidualBlock` class below with 2 convolutional layers and residual connection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRgTxZTFQyNu"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, down_sample=False):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=?,\n",
        "                     stride=?, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=?,\n",
        "                             stride=?, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.down_sample = down_sample\n",
        "        self.stride = stride\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "    def down_sampling(self, x):\n",
        "        out = F.pad(x, (0, 0, 0, 0, 0, self.out_channels - self.in_channels))\n",
        "        out = nn.MaxPool2d(2, stride=self.stride)(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x # this will be used to build residual connection.\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        #############################################\n",
        "        # Implement here using down_sampling method #\n",
        "        #############################################\n",
        "\n",
        "        out += shortcut # residual connection\n",
        "        out = self.relu(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5GJthPiQyNu"
      },
      "source": [
        "`ResidualBlock` class which extends `torch.nn.Module`. `ResidualBlock` class receives `in_channels`, `out_channels`, `stride` and `down_sample`.\n",
        "\n",
        "In ResNet, there are residual blocks that twice the output channel(16 to 32, 32 to 64). The `stride` argument for `ResidualBlock` is set to 2 in such residual blocks to down sample (reduce spatial dimension) while increasing channels.\n",
        "\n",
        "However, the residual connection in the residual block can occur dimension mismatch since the output of other path (through convolutional layers) change the dimension of input with `stride=2`. Thus, residual block should support downsample through the residual connection in demand.\n",
        "\n",
        "We support this feature in `down_sampling` method in `ResidualBlock` class. It conducts zero-padding to exapnd the channels and max-pooling to shrink spatial dimension through residual block. Using `down_sampling` in the middle of the `forward` method to handle `down_sample` condition to residual connection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xjLIGAcQyNu"
      },
      "source": [
        "### 2.2. ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooORqUAuQyNu"
      },
      "source": [
        "Now implement `ResNet` class. Assume the `block` argument will be `ResidualBlock` we implemented above. Here are required implementation details.\n",
        "\n",
        "* In `init` method, specifiy all details of convolution, batch norm layers.\n",
        "* In `get_layers` method, set down_sample boolean variable according to the stride information. Then, define a list of residual blocks (`layer_list`). Make sure the down-sample only occurs at the first block in demand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zD_6onUZQyNv"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_layers, block, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        #input(channel:3) -> (conv 3x3) -> (bn) -> (relu) -> output(channel:16)\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=?,\n",
        "            out_channels=?,\n",
        "            kernel_size=?,\n",
        "            stride=?,\n",
        "            padding=1,\n",
        "            bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(??)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # feature map size = 16x32x32\n",
        "        self.layers_2n = self.get_layers(block, ??, ??, stride=?)\n",
        "        # feature map size = 32x16x16\n",
        "        self.layers_4n = self.get_layers(block, ??, ??, stride=?)\n",
        "        # feature map size = 64x8x8\n",
        "        self.layers_6n = self.get_layers(block, ??, ??, stride=?)\n",
        "\n",
        "        # output layers\n",
        "        self.avg_pool = nn.AvgPool2d(?, stride=1)\n",
        "        self.fc_out = nn.Linear(?, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "    def get_layers(self, block, in_channels, out_channels, stride):\n",
        "        if stride == 2:\n",
        "            down_sample = ??\n",
        "        else:\n",
        "            down_sample = ??\n",
        "\n",
        "        layer_list = nn.ModuleList([])\n",
        "\n",
        "        ##############################\n",
        "        # Implement here: layer_list #\n",
        "        ##############################\n",
        "\n",
        "        return nn.Sequential(*layer_list)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layers_2n(x)\n",
        "        x = self.layers_4n(x)\n",
        "        x = self.layers_6n(x)\n",
        "\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_out(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu1f3oqkQyNv"
      },
      "source": [
        "In this practice we use resnet32 to train CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSReePRRQyNv"
      },
      "outputs": [],
      "source": [
        "def resnet18():\n",
        "    block = ResidualBlock\n",
        "    model = ResNet(3, block)\n",
        "    return model\n",
        "def resnet32():\n",
        "    block = ResidualBlock\n",
        "    model = ResNet(5, block)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMlHjUGgQyNv"
      },
      "source": [
        "By replacing `ResidualBlock` with plain `Block` (without residual connection), we can compare the effectiveness of residual connection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cniEGap1QyNw"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, down_sample=False):\n",
        "        super(Block, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
        "                     stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
        "                             stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.stride = stride\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAH9hrr0QyNw"
      },
      "outputs": [],
      "source": [
        "def cnn18():\n",
        "    block = Block\n",
        "    model = ResNet(3, block)\n",
        "    return model\n",
        "\n",
        "def cnn32():\n",
        "    block = Block\n",
        "    model = ResNet(5, block)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAHhqxm8QyNw"
      },
      "source": [
        "### 2.3. Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDOa9ayiQyNw"
      },
      "source": [
        "Training resnet is not different with other training schemes. We train 64000 batch steps with 128 batch size. The learning rate starts from 0.1 and is decayed at 32,000 and 48,000 step with 0.1 factor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJPJOhzjQyNw"
      },
      "outputs": [],
      "source": [
        "net = resnet18().to(device)\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "decay_epoch = [32000, 48000]\n",
        "step_lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JSrFeDjQyNw"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "net.train()\n",
        "\n",
        "step = 0\n",
        "epochs = 0\n",
        "losses = []\n",
        "\n",
        "while step < 64000:\n",
        "\n",
        "    train_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(cifar_loader['train']):\n",
        "        step += 1\n",
        "        step_lr_scheduler.step()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        out = net(x)\n",
        "        loss = criterion(out, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        correct += (out.argmax(1) == y).float().sum().item()\n",
        "        total += x.size(0)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    losses.append(train_loss)\n",
        "    epochs += 1\n",
        "\n",
        "    print(\"Epoch[{:d} ({:d}/64000) ({:.4f}sec)] loss: {:.2f} acc: {:.2f}\".format(epochs, step, time.time()-start_time, train_loss, 100.*correct/total))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAj8nj8EQyNx"
      },
      "source": [
        "Plot train loss and calculate test performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OciTdiOwQyNx"
      },
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-WMpx0EQyNx"
      },
      "outputs": [],
      "source": [
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWQzd7dYQyNx"
      },
      "outputs": [],
      "source": [
        "net.eval()\n",
        "test_correct = 0.0\n",
        "test_total = 0.0\n",
        "for batch_idx, (x, y) in enumerate(cifar_loader['test']):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    out = net(x)\n",
        "    test_correct += (out.argmax(1) == y).float().sum().item()\n",
        "    test_total += x.size(0)\n",
        "\n",
        "print(test_correct/test_total * 100.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HohO9gEQyNx"
      },
      "source": [
        "Train CNNs wihtout residual connection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DFqlUn9QyNy"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "net_plain = cnn18().to(device)\n",
        "optimizer = torch.optim.SGD(net_plain.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
        "decay_epoch = [32000, 48000]\n",
        "step_lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma=0.1)\n",
        "\n",
        "net_plain.train()\n",
        "\n",
        "step = 0\n",
        "epochs = 0\n",
        "losses_plain = []\n",
        "\n",
        "while step < 64000:\n",
        "\n",
        "    train_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(cifar_loader['train']):\n",
        "        step += 1\n",
        "        step_lr_scheduler.step()\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        out = net_plain(x)\n",
        "        loss = criterion(out, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        correct += (out.argmax(1) == y).float().sum().item()\n",
        "        total += x.size(0)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    losses_plain.append(train_loss)\n",
        "    epochs += 1\n",
        "\n",
        "    print(\"Epoch[{:d} ({:d}/64000) ({:.4f}sec)] loss: {:.2f} acc: {:.2f}\".format(epochs, step, time.time()-start_time, train_loss, 100.*correct/total))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFPA_PB6QyNy"
      },
      "source": [
        "Plot train loss and calculate test performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voB2cdmDQyNy"
      },
      "outputs": [],
      "source": [
        "plt.plot(losses, label='resnet')\n",
        "plt.plot(losses_plain, label='cnn')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gfxrc6WzQyNy"
      },
      "outputs": [],
      "source": [
        "net_plain.eval()\n",
        "test_correct = 0.0\n",
        "test_total = 0.0\n",
        "for batch_idx, (x, y) in enumerate(cifar_loader['test']):\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    out = net_plain(x)\n",
        "    test_correct += (out.argmax(1) == y).float().sum().item()\n",
        "    test_total += x.size(0)\n",
        "\n",
        "print(test_correct/test_total * 100.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcMMMfTGQyNy"
      },
      "source": [
        "### Reference\n",
        "* https://tutorials.pytorch.kr/beginner/blitz/neural_networks_tutorial.html\n",
        "* https://github.com/dnddnjs/pytorch-cifar10/blob/enas/resnet/model.py\n",
        "* https://icml.cc/2016/tutorials/icml2016_tutorial_deep_residual_networks_kaiminghe.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deCXcx2TQyNz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}